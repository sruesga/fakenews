{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Preprocessing\n",
    "This notebook details the data cleaning and tokenization needed for our models.\n",
    "\n",
    "For the original dataset, visit [here](https://github.com/several27/FakeNewsCorpus). The dataset is about 9.5GB zipped and 30GB unzipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "import gzip\n",
    "import shutil\n",
    "from segtok import tokenizer\n",
    "from collections import Counter\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_dataset = \"data/raw/news_cleaned_2018_02_13.csv\"\n",
    "new_dataset = \"data/clean/fake_reliable_news_headlines.csv\"\n",
    "\n",
    "columns = {'id':int, 'type':str, 'title':str}\n",
    "allowable_types = ['fake', 'reliable']\n",
    "\n",
    "chunksize = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the new dataset as a csv\n",
    "with open(old_dataset, 'r') as f_old, open(new_dataset, 'w') as f_new:\n",
    "    f_new.write(','.join(columns.keys()) + '\\n')\n",
    "    for df in pd.read_csv(f_old, chunksize=chunksize, error_bad_lines=False):\n",
    "        df = df.loc[:, columns]\n",
    "        df = df[df['type'].isin(allowable_types)]\n",
    "        df.to_csv(f_new, header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional to gzip csv, this takes a while\n",
    "with open(new_dataset, 'rb') as f_in, gzip.open(new_dataset+'.gz', 'wb') as f_out:\n",
    "        shutil.copyfileobj(f_in, f_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>34</td>\n",
       "      <td>fake</td>\n",
       "      <td>Surprise: Socialist Hotbed Of Venezuela Has Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>fake</td>\n",
       "      <td>Water Cooler 1/25/18 Open Thread; Fake News ? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>fake</td>\n",
       "      <td>Veteran Commentator Calls Out the Growing “Eth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>fake</td>\n",
       "      <td>Lost Words, Hidden Words, Otters, Banks and Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>fake</td>\n",
       "      <td>Red Alert: Bond Yields Are SCREAMING “Inflatio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  type                                              title\n",
       "0  34  fake  Surprise: Socialist Hotbed Of Venezuela Has Lo...\n",
       "1  35  fake  Water Cooler 1/25/18 Open Thread; Fake News ? ...\n",
       "2  36  fake  Veteran Commentator Calls Out the Growing “Eth...\n",
       "3  37  fake  Lost Words, Hidden Words, Otters, Banks and Books\n",
       "4  38  fake  Red Alert: Bond Yields Are SCREAMING “Inflatio..."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset = pd.read_csv(new_dataset, dtype=columns)\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(894746, 3) (1913222, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id        int64\n",
       "type     object\n",
       "title    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fake = df_dataset[df_dataset.type == 'fake']\n",
    "df_reliable = df_dataset[df_dataset.type == 'reliable']\n",
    "print(df_fake.shape, df_reliable.shape)\n",
    "df_fake.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8848385</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Dude, You're Getting A Loan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9381772</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Popularity of Juniors Tournament Crosses Border</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7995139</td>\n",
       "      <td>reliable</td>\n",
       "      <td>After IS kidnap and oppression, Iraqi girls ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3171691</td>\n",
       "      <td>fake</td>\n",
       "      <td>Is The Internet Private Property Now?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3147319</td>\n",
       "      <td>fake</td>\n",
       "      <td>DOJ Broke It’s Own rules In AP Investigation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      type                                              title\n",
       "0  8848385  reliable                        Dude, You're Getting A Loan\n",
       "1  9381772  reliable    Popularity of Juniors Tournament Crosses Border\n",
       "2  7995139  reliable  After IS kidnap and oppression, Iraqi girls ea...\n",
       "3  3171691      fake              Is The Internet Private Property Now?\n",
       "4  3147319      fake       DOJ Broke It’s Own rules In AP Investigation"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_size = 100000\n",
    "df_dataset = sk.utils.shuffle(pd.concat([df_fake.sample(sample_size), df_reliable.sample(sample_size)]))\n",
    "df_dataset.reset_index(inplace=True, drop=True)\n",
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(',', 56353), ('the', 49546), (':', 41714), ('to', 34696), ('in', 30599), ('of', 29100), ('a', 25239), ('and', 22009), ('for', 20236), ('on', 15788), ('is', 11447), ('?', 10183), ('–', 9756), ('paid', 9026), ('notice', 8970), ('with', 8708), ('new', 8301), ('deaths', 8254), ('at', 7973), ('(', 6765), (')', 6703), ('‘', 6183), ('by', 6098), ('-', 5997), ('!', 5987), ('.', 5820), (\"'\", 5792), ('from', 5728), (';', 5119), ('as', 5063)]\n"
     ]
    }
   ],
   "source": [
    "df_dataset['tokenized'] = np.nan\n",
    "df_dataset['tokenized'] = df_dataset['tokenized'].astype(object)\n",
    "word_counts = Counter()\n",
    "for i, row in df_dataset.iterrows():\n",
    "    df_dataset.at[i, 'tokenized'] = tokenizer.word_tokenizer(str(row['title']).lower())\n",
    "    word_counts.update(df_dataset.loc[i, 'tokenized'])\n",
    "print(word_counts.most_common(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the vocab\n",
    "vocab_size = 20000\n",
    "special_words = [\"<START>\", \"UNK\", \"PAD\"]\n",
    "vocabulary = special_words + [w for w, c in word_counts.most_common(vocab_size-len(special_words))]\n",
    "w2i = {w: i for i, w in enumerate(vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerizing and padding\n",
    "input_length = 20\n",
    "unkI, padI, startI = w2i['UNK'], w2i['PAD'], w2i['<START>']\n",
    "\n",
    "def numerize_sequence(tokenized):\n",
    "    return [w2i.get(w, unkI) for w in tokenized]\n",
    "\n",
    "def pad_sequence(numerized, pad_index, to_length):\n",
    "    pad = numerized[:to_length]\n",
    "    padded = pad + [pad_index] * (to_length - len(pad))\n",
    "    mask = [w != pad_index for w in padded]\n",
    "    return padded, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dataset['numerized'] = np.nan\n",
    "df_dataset['numerized'] = df_dataset['numerized'].astype(object)\n",
    "df_dataset['mask'] = np.nan\n",
    "df_dataset['mask'] = df_dataset['mask'].astype(object)\n",
    "for i, row in df_dataset.iterrows():\n",
    "    df_dataset.at[i, 'numerized'] = numerize_sequence(row['tokenized']) # Change words to IDs\n",
    "    df_dataset.at[i, 'numerized'], df_dataset.at[i, 'mask'] = pad_sequence(df_dataset.loc[i, 'numerized'], padI, input_length) # Append appropriate PAD tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraction of UNK words: 0.08393581712373868\n"
     ]
    }
   ],
   "source": [
    "# Compute fraction of words that are UNK:\n",
    "word_counters = Counter([w for i, r in df_dataset.iterrows() for w in r['numerized'] if w != padI])\n",
    "print(\"Fraction of UNK words:\", float(word_counters[unkI]) / sum(word_counters.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>type</th>\n",
       "      <th>title</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>numerized</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8848385</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Dude, You're Getting A Loan</td>\n",
       "      <td>[dude, ,, you're, getting, a, loan]</td>\n",
       "      <td>[6941, 3, 3649, 548, 9, 2020, 2, 2, 2, 2, 2, 2...</td>\n",
       "      <td>[True, True, True, True, True, True, False, Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9381772</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Popularity of Juniors Tournament Crosses Border</td>\n",
       "      <td>[popularity, of, juniors, tournament, crosses,...</td>\n",
       "      <td>[9743, 8, 1, 4547, 7050, 737, 2, 2, 2, 2, 2, 2...</td>\n",
       "      <td>[True, True, True, True, True, True, False, Fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7995139</td>\n",
       "      <td>reliable</td>\n",
       "      <td>After IS kidnap and oppression, Iraqi girls ea...</td>\n",
       "      <td>[after, is, kidnap, and, oppression, ,, iraqi,...</td>\n",
       "      <td>[45, 13, 9351, 10, 1, 3, 1054, 1256, 7027, 6, ...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3171691</td>\n",
       "      <td>fake</td>\n",
       "      <td>Is The Internet Private Property Now?</td>\n",
       "      <td>[is, the, internet, private, property, now, ?]</td>\n",
       "      <td>[13, 4, 141, 665, 1328, 73, 14, 2, 2, 2, 2, 2,...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3147319</td>\n",
       "      <td>fake</td>\n",
       "      <td>DOJ Broke It’s Own rules In AP Investigation</td>\n",
       "      <td>[doj, broke, it’s, own, rules, in, ap, investi...</td>\n",
       "      <td>[3685, 4277, 191, 355, 435, 7, 2880, 1036, 2, ...</td>\n",
       "      <td>[True, True, True, True, True, True, True, Tru...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      type                                              title  \\\n",
       "0  8848385  reliable                        Dude, You're Getting A Loan   \n",
       "1  9381772  reliable    Popularity of Juniors Tournament Crosses Border   \n",
       "2  7995139  reliable  After IS kidnap and oppression, Iraqi girls ea...   \n",
       "3  3171691      fake              Is The Internet Private Property Now?   \n",
       "4  3147319      fake       DOJ Broke It’s Own rules In AP Investigation   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0                [dude, ,, you're, getting, a, loan]   \n",
       "1  [popularity, of, juniors, tournament, crosses,...   \n",
       "2  [after, is, kidnap, and, oppression, ,, iraqi,...   \n",
       "3     [is, the, internet, private, property, now, ?]   \n",
       "4  [doj, broke, it’s, own, rules, in, ap, investi...   \n",
       "\n",
       "                                           numerized  \\\n",
       "0  [6941, 3, 3649, 548, 9, 2020, 2, 2, 2, 2, 2, 2...   \n",
       "1  [9743, 8, 1, 4547, 7050, 737, 2, 2, 2, 2, 2, 2...   \n",
       "2  [45, 13, 9351, 10, 1, 3, 1054, 1256, 7027, 6, ...   \n",
       "3  [13, 4, 141, 665, 1328, 73, 14, 2, 2, 2, 2, 2,...   \n",
       "4  [3685, 4277, 191, 355, 435, 7, 2880, 1036, 2, ...   \n",
       "\n",
       "                                                mask  \n",
       "0  [True, True, True, True, True, True, False, Fa...  \n",
       "1  [True, True, True, True, True, True, False, Fa...  \n",
       "2  [True, True, True, True, True, True, True, Tru...  \n",
       "3  [True, True, True, True, True, True, True, Fal...  \n",
       "4  [True, True, True, True, True, True, True, Tru...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_dataset = \"data/processed/fake_reliable_news_headlines.json.gz\"\n",
    "df_dataset.to_json(processed_dataset, compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
